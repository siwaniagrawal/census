{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tempfile\n",
    "import urllib\n",
    "train_file = tempfile.NamedTemporaryFile()\n",
    "test_file = tempfile.NamedTemporaryFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
      "       'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
      "       'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
      "       'income_bracket'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "CSV_COLUMNS = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "    \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "    \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n",
    "    \"income_bracket\"]\n",
    "df_train = pd.read_csv(\"./adult_data.csv\", names=CSV_COLUMNS, skipinitialspace=True)\n",
    "df_test = pd.read_csv(\"./adult_test.csv\", names=CSV_COLUMNS, skipinitialspace=True, skiprows=1)\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=(df_train[\"income_bracket\"].apply(lambda x:\">50k\" in x)).astype(int)\n",
    "test_labels = (df_test[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(data_file, num_epochs, shuffle):\n",
    "  \"\"\"Input builder function.\"\"\"\n",
    "  df_data = pd.read_csv(\n",
    "      tf.gfile.Open(data_file),\n",
    "      names=CSV_COLUMNS,\n",
    "      skipinitialspace=True,\n",
    "      engine=\"python\",\n",
    "      skiprows=1)\n",
    "  # remove NaN elements\n",
    "  df_data = df_data.dropna(how=\"any\", axis=0)\n",
    "  labels = df_data[\"income_bracket\"].apply(lambda x: \">50K\" in x).astype(int)\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "      x=df_data,\n",
    "      y=labels,\n",
    "      batch_size=100,\n",
    "      num_epochs=num_epochs,\n",
    "      shuffle=shuffle,\n",
    "      num_threads=5)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gender = tf.feature_column.categorical_column_with_vocabulary_list(\"gender\",[\"female\",\"male\"])\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"occupation\", hash_bucket_size=1000)\n",
    "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"education\", [\n",
    "        \"Bachelors\", \"HS-grad\", \"11th\", \"Masters\", \"9th\",\n",
    "        \"Some-college\", \"Assoc-acdm\", \"Assoc-voc\", \"7th-8th\",\n",
    "        \"Doctorate\", \"Prof-school\", \"5th-6th\", \"10th\", \"1st-4th\",\n",
    "        \"Preschool\", \"12th\"\n",
    "    ])\n",
    "marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"marital_status\", [\n",
    "        \"Married-civ-spouse\", \"Divorced\", \"Married-spouse-absent\",\n",
    "        \"Never-married\", \"Separated\", \"Married-AF-spouse\", \"Widowed\"\n",
    "    ])\n",
    "relationship = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"relationship\", [\n",
    "        \"Husband\", \"Not-in-family\", \"Wife\", \"Own-child\", \"Unmarried\",\n",
    "        \"Other-relative\"\n",
    "    ])\n",
    "workclass = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"workclass\", [\n",
    "        \"Self-emp-not-inc\", \"Private\", \"State-gov\", \"Federal-gov\",\n",
    "        \"Local-gov\", \"?\", \"Self-emp-inc\", \"Without-pay\", \"Never-worked\"\n",
    "    ])\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"native_country\", hash_bucket_size=1000)\n",
    "#for continuous data\n",
    "age=tf.feature_column.numeric_column(\"age\")\n",
    "education_num = tf.feature_column.numeric_column(\"education_num\")\n",
    "capital_gain = tf.feature_column.numeric_column(\"capital_gain\")\n",
    "capital_loss = tf.feature_column.numeric_column(\"capital_loss\")\n",
    "hours_per_week = tf.feature_column.numeric_column(\"hours_per_week\")\n",
    "\n",
    "#bucketized columns\n",
    "age_buckets=tf.feature_column.bucketized_column(age, boundaries=[18,25,  30, 35, 40, 45, 50, 55, 60, 65])\n",
    "education_x_occupation = tf.feature_column.crossed_column(\n",
    "    [\"education\", \"occupation\"], hash_bucket_size=1000)\n",
    "age_buckets_x_education_x_occupation = tf.feature_column.crossed_column([age_buckets,\"education\",\"occupation\"],\n",
    "                                                                       hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpolu2e66z', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f723547f8d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "base_columns = [\n",
    "    gender, native_country, education, occupation, workclass, relationship,\n",
    "    age_buckets,\n",
    "]\n",
    "crossed_columns = [\n",
    "    tf.feature_column.crossed_column(\n",
    "        [\"education\", \"occupation\"], hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(\n",
    "        [age_buckets, \"education\", \"occupation\"], hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(\n",
    "        [\"native_country\", \"occupation\"], hash_bucket_size=1000)\n",
    "]\n",
    "\n",
    "\n",
    "model_dir = tempfile.mkdtemp()\n",
    "m= tf.estimator.LinearClassifier(model_dir = model_dir, feature_columns= base_columns + crossed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpolu2e66z/model.ckpt.\n",
      "INFO:tensorflow:loss = 69.31472, step = 1\n",
      "INFO:tensorflow:global_step/sec: 83.7671\n",
      "INFO:tensorflow:loss = 36.77567, step = 101 (1.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.712\n",
      "INFO:tensorflow:loss = 28.358149, step = 201 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.983\n",
      "INFO:tensorflow:loss = 29.087587, step = 301 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.31\n",
      "INFO:tensorflow:loss = 40.878227, step = 401 (0.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.174\n",
      "INFO:tensorflow:loss = 36.946056, step = 501 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.902\n",
      "INFO:tensorflow:loss = 28.819906, step = 601 (0.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.228\n",
      "INFO:tensorflow:loss = 39.874992, step = 701 (0.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.06\n",
      "INFO:tensorflow:loss = 28.886816, step = 801 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.118\n",
      "INFO:tensorflow:loss = 34.298367, step = 901 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.734\n",
      "INFO:tensorflow:loss = 31.211218, step = 1001 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.364\n",
      "INFO:tensorflow:loss = 38.188496, step = 1101 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.934\n",
      "INFO:tensorflow:loss = 33.767326, step = 1201 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.741\n",
      "INFO:tensorflow:loss = 33.539364, step = 1301 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.741\n",
      "INFO:tensorflow:loss = 33.205837, step = 1401 (0.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.492\n",
      "INFO:tensorflow:loss = 27.364454, step = 1501 (0.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.08\n",
      "INFO:tensorflow:loss = 40.47276, step = 1601 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.341\n",
      "INFO:tensorflow:loss = 28.984228, step = 1701 (0.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.444\n",
      "INFO:tensorflow:loss = 33.51432, step = 1801 (0.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.081\n",
      "INFO:tensorflow:loss = 33.62141, step = 1901 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.972\n",
      "INFO:tensorflow:loss = 31.714148, step = 2001 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.69\n",
      "INFO:tensorflow:loss = 30.261492, step = 2101 (0.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.72\n",
      "INFO:tensorflow:loss = 37.055252, step = 2201 (0.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.709\n",
      "INFO:tensorflow:loss = 31.174484, step = 2301 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.512\n",
      "INFO:tensorflow:loss = 28.229177, step = 2401 (0.635 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into /tmp/tmpolu2e66z/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 35.89898.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7f723531b1d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.train(\n",
    "    input_fn=input_fn(\"./adult_data.csv\" , num_epochs=None, shuffle=True),\n",
    "    steps=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=False and num_threads > 1. This will create multiple threads, all reading the array/dataframe in order. If you want examples read in order, use one thread; if you want multiple threads, enable shuffling.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-07-16:49:03\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpolu2e66z/model.ckpt-2500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-07-16:49:10\n",
      "INFO:tensorflow:Saving dict for global step 2500: accuracy = 0.83256555, accuracy_baseline = 0.76377374, auc = 0.87981945, auc_precision_recall = 0.6895981, average_loss = 0.35740533, global_step = 2500, label/mean = 0.23622628, loss = 35.698875, precision = 0.66746414, prediction/mean = 0.24696377, recall = 0.5803432\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2500: /tmp/tmpolu2e66z/model.ckpt-2500\n",
      "model directory = /tmp/tmpolu2e66z\n",
      "accuracy: 0.83256555\n",
      "accuracy_baseline: 0.76377374\n",
      "auc: 0.87981945\n",
      "auc_precision_recall: 0.6895981\n",
      "average_loss: 0.35740533\n",
      "global_step: 2500\n",
      "label/mean: 0.23622628\n",
      "loss: 35.698875\n",
      "precision: 0.66746414\n",
      "prediction/mean: 0.24696377\n",
      "recall: 0.5803432\n"
     ]
    }
   ],
   "source": [
    "results = m.evaluate(\n",
    "    input_fn=input_fn(\"./adult_test.csv\", num_epochs=1, shuffle=False),\n",
    "    steps=None)\n",
    "print(\"model directory = %s\" % model_dir)\n",
    "for key in sorted(results):\n",
    "  print(\"%s: %s\" % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated (<ipython-input-60-f5931b663b03>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-60-f5931b663b03>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    model_dir=model_dir )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated\n"
     ]
    }
   ],
   "source": [
    "m = tf.estimator.LinearClassifier(\n",
    "    model_dir=model_dir, feature_columns=base_columns + crossed_columns,\n",
    "    optimizer=tf.train.FtrlOptimizer(\n",
    "      learning_rate=0.1,\n",
    "      l1_regularization_strength=1.0,\n",
    "      l2_regularization_strength=1.0),\n",
    "    model_dir =model_dir )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
